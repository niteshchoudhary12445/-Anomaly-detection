{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyMvX1O5NZb0MM1SnikD8eMk",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/niteshchoudhary12445/-Anomaly-detection/blob/main/Anomaly_detection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Anomaly Detection"
      ],
      "metadata": {
        "id": "prCel00Y8tF2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.Data Import and Exploration"
      ],
      "metadata": {
        "id": "gS61rZEQ88FG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow==2.16.1"
      ],
      "metadata": {
        "id": "ztV6RRwcHolm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3_djncoBRynz"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_excel(\"/content/AssignmentData.xlsx\",sheet_name=2)"
      ],
      "metadata": {
        "id": "y2YDbRseUtI5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data"
      ],
      "metadata": {
        "id": "zCZdf_KlXNpm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.info()"
      ],
      "metadata": {
        "id": "ofKcc9fmVKPW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data['Class'].value_counts()"
      ],
      "metadata": {
        "id": "QUPEOl5qWvu7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.hist(bins=50,figsize=(30,20))"
      ],
      "metadata": {
        "id": "f4mVKUaZXerf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.Feature Engineering"
      ],
      "metadata": {
        "id": "tgN3aW6q9IwQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import RobustScaler\n",
        "new_df = data.copy()\n",
        "new_df[\"Amount\"] = RobustScaler().fit_transform(new_df[\"Amount\"].values.reshape(-1,1))"
      ],
      "metadata": {
        "id": "TOVoOVQcYViJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_df"
      ],
      "metadata": {
        "id": "ZkX8aaOXZcSf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "minmax_scaler = MinMaxScaler()\n",
        "new_df[[\"Time\"]] = minmax_scaler.fit_transform(new_df[[\"Time\"]])"
      ],
      "metadata": {
        "id": "FmJAR66MZnti"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_df"
      ],
      "metadata": {
        "id": "lL7Ctzi_aQY1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "col_to_convert = [\"V2\",\"V7\",\"V9\",\"V24\"]\n",
        "for col in col_to_convert:\n",
        "  new_df[col] = pd.to_numeric(new_df[col],errors='coerce')"
      ],
      "metadata": {
        "id": "FHmyEmQTaSDd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_df.info()"
      ],
      "metadata": {
        "id": "q5H-R_AVa4ME"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for col in col_to_convert:\n",
        "  new_df = new_df.dropna(subset=[col],axis=0)"
      ],
      "metadata": {
        "id": "5lBPxW_5biXg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_df.info()"
      ],
      "metadata": {
        "id": "W3Qq7Y_-b_dt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.Visualizing the Anamolies"
      ],
      "metadata": {
        "id": "nRGAPVFu-BB5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.decomposition import PCA\n",
        "\n",
        "pca = PCA(n_components=2)\n",
        "new_df_pca = pca.fit_transform(new_df.drop(columns=['Class']))\n",
        "\n",
        "# Add the PCA features to the dataframe\n",
        "new_df['PCA1'] = new_df_pca[:, 0]\n",
        "new_df['PCA2'] = new_df_pca[:, 1]\n",
        "\n",
        "# Visualize the data in 2D\n",
        "sns.scatterplot(x='PCA1', y='PCA2', hue='Class', data=new_df, palette={0: 'blue', 1: 'red'})\n",
        "plt.title('PCA of Transactions')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "HEUYGgvrhCW4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the dataset\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train,X_test,y_train,y_test = train_test_split(new_df.drop(\"Class\",axis=1),new_df[\"Class\"],test_size=0.2,random_state=42)"
      ],
      "metadata": {
        "id": "SoUZ3OQXceTB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.shape,y_train.shape"
      ],
      "metadata": {
        "id": "wQbvvCF2c8LS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_test.shape,y_test.shape"
      ],
      "metadata": {
        "id": "tfoAjNJrdBm8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_train.value_counts()"
      ],
      "metadata": {
        "id": "pIGF9A-edGu2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_test.value_counts()"
      ],
      "metadata": {
        "id": "ERTjXd5Bdace"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4.Anomaly Detection Model"
      ],
      "metadata": {
        "id": "_ODwzHBt9fzh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import IsolationForest\n",
        "from sklearn.metrics import classification_report, roc_auc_score\n",
        "\n",
        "# Initialize Isolation Forest\n",
        "iso_forest_model = IsolationForest(contamination=0.0017)  # Set contamination to the percentage of fraudulent transactions\n",
        "iso_forest_model.fit(X_train)\n",
        "\n",
        "# Predict anomalies\n",
        "y_pred = iso_forest_model.predict(X_test)\n",
        "y_pred = pd.Series(y_pred).map({1: 0, -1: 1})\n",
        "\n",
        "# Evaluation\n",
        "print(classification_report(y_test, y_pred))\n",
        "print(\"ROC-AUC Score:\", roc_auc_score(y_test, y_pred))\n"
      ],
      "metadata": {
        "id": "evizKhuUgdLk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This model predicting anamolies with 19% and ROC-AUC Score is 0.59031126768893388 which means it's basically guessing"
      ],
      "metadata": {
        "id": "-g-HMUCULMq-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "counts = pd.Series(y_pred).value_counts()\n",
        "print(counts)"
      ],
      "metadata": {
        "id": "olhBg88DigvE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle as pkl\n",
        "with open(\"iso_forest_model.pkl\",\"wb\") as f:\n",
        "  pkl.dump(iso_forest_model,f)\n"
      ],
      "metadata": {
        "id": "52Mi8OBBwFdy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "# Prepare the train_dataset\n",
        "train_features = tf.data.Dataset.from_tensor_slices(X_train)\n",
        "train_labels = tf.data.Dataset.from_tensor_slices(y_train)\n",
        "train_dataset = tf.data.Dataset.zip((train_features,train_labels)).batch(1024).prefetch(tf.data.AUTOTUNE)"
      ],
      "metadata": {
        "id": "Q29CcvMljw44"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Prepare the test_dataset\n",
        "test_features = tf.data.Dataset.from_tensor_slices(X_test)\n",
        "test_labels = tf.data.Dataset.from_tensor_slices(y_test)\n",
        "test_dataset = tf.data.Dataset.zip((test_features,test_labels)).batch(1024).prefetch(tf.data.AUTOTUNE)"
      ],
      "metadata": {
        "id": "cLJEHq9zw2j3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_train.shape"
      ],
      "metadata": {
        "id": "kUf4qzGozFSI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_dims = X_train.shape[1]\n",
        "input_dims"
      ],
      "metadata": {
        "id": "auHOdNLnxwjw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.models import Model\n",
        "inputs = layers.Input(shape=(input_dims,), name=\"Input_layer\")\n",
        "encoded = layers.Dense(128, activation=\"relu\")(inputs)\n",
        "encoded = layers.Dense(64, activation=\"relu\")(encoded)  # Smaller dimension (Latent space)\n",
        "encoded = layers.Dense(32, activation=\"relu\")(encoded)\n",
        "drop_layer = layers.Dropout(0.5)(encoded)\n",
        "# Latent space (bottleneck)\n",
        "latent_space = layers.Dense(16, activation=\"relu\", name=\"Latent_space\")(drop_layer)\n",
        "\n",
        "# Decoder\n",
        "decoded = layers.Dense(32, activation=\"relu\")(latent_space)\n",
        "decoded = layers.Dense(64, activation=\"relu\")(decoded)\n",
        "decoded = layers.Dense(128, activation=\"relu\")(decoded)\n",
        "drop_layer = layers.Dropout(0.5)(decoded)\n",
        "outputs = layers.Dense(1, activation=\"sigmoid\")(drop_layer)\n",
        "\n",
        "# Autoencoder model\n",
        "autoencoder_model = Model(inputs=inputs, outputs=outputs)"
      ],
      "metadata": {
        "id": "CBpvo7INvnQn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "autoencoder_model.summary()"
      ],
      "metadata": {
        "id": "l2o4kyACzlUt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile the model\n",
        "autoencoder_model.compile(loss=\"binary_crossentropy\",optimizer=\"adam\")"
      ],
      "metadata": {
        "id": "9_R6xCWXzogh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "file_path = \"/content/Models/autoencoder_model5.keras\""
      ],
      "metadata": {
        "id": "Nq9875KP1UzY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Set up the ModelCheckpoint callback\n",
        "checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath=file_path,\n",
        "    monitor=\"val_loss\",\n",
        "    save_best_only=True,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# Set up the ReduceLROnPlateau callback\n",
        "reduce_lr_callback = tf.keras.callbacks.ReduceLROnPlateau(\n",
        "    monitor=\"val_loss\",\n",
        "    factor=0.5,          # Factor by which the learning rate will be reduced\n",
        "    patience=5,          # Number of epochs with no improvement after which learning rate will be reduced\n",
        "    verbose=1,           # Print a message when the learning rate is reduced\n",
        "    min_lr=1e-6          # Lower bound on the learning rate\n",
        ")\n",
        "\n",
        "# Fit the autoencoder models\n",
        "history = autoencoder_model.fit(\n",
        "    train_dataset,\n",
        "    epochs=50,\n",
        "    validation_data=test_dataset,\n",
        "    callbacks=[checkpoint_callback, reduce_lr_callback]\n",
        ")\n"
      ],
      "metadata": {
        "id": "shAZ-1HC0msZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "autoencoder_model.evaluate(test_dataset)"
      ],
      "metadata": {
        "id": "hcCiJJdf1lU4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "load_model = tf.keras.models.load_model(\"/content/Models/autoencoder_model5.keras\")"
      ],
      "metadata": {
        "id": "l8aaoc645jPs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "load_model.evaluate(test_dataset)"
      ],
      "metadata": {
        "id": "0DwFiMi653S_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_features = test_features.batch(1024).prefetch(tf.data.AUTOTUNE)"
      ],
      "metadata": {
        "id": "9eDQG85f6Jvt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_features"
      ],
      "metadata": {
        "id": "bzdsS9FpA1LE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "autoencoder_y_pred = load_model.predict(X_test)"
      ],
      "metadata": {
        "id": "GkdFVVYe58uj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "autoencoder_y_pred = tf.squeeze(tf.round(autoencoder_y_pred))"
      ],
      "metadata": {
        "id": "Ogd2Qs-X-D7G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "unique_val, counts = np.unique(autoencoder_y_pred,return_counts=True)\n",
        "for val,count in zip(unique_val,counts):\n",
        "  print(f\"Value: {val}  Count: {count}\\n\")"
      ],
      "metadata": {
        "id": "JgK2znUn8dO3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(y_test, autoencoder_y_pred))\n",
        "print(\"ROC-AUC Score:\", roc_auc_score(y_test, autoencoder_y_pred))"
      ],
      "metadata": {
        "id": "mvrrrhEp6IC5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This model predicting anamolies with 82% accuracy"
      ],
      "metadata": {
        "id": "vGoZQWomK3L2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "load_model.save(\"Autoencoder_model_streamlit.keras\")"
      ],
      "metadata": {
        "id": "GnSXDcaHITDk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download(\"/content/Autoencoder_model_streamlit.keras\")"
      ],
      "metadata": {
        "id": "El4agfNMTAVP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5.Write a function that accepts a new dataset of credit card transactions and the trained anomaly detection model, returning a list of transactions classified as fraudulent."
      ],
      "metadata": {
        "id": "6BVeV0rkpIz_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Ensure the new data has the same features as the model was trained on\n",
        "def detect_fraudulent_transactions(new_data: pd.DataFrame, model) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Detects fraudulent transactions from a new dataset using a trained anomaly detection model.\n",
        "\n",
        "    Parameters:\n",
        "    - new_data: pd.DataFrame. The new dataset containing credit card transactions.\n",
        "    - model: A trained anomaly detection model that can predict whether a transaction is fraudulent.\n",
        "\n",
        "    Returns:\n",
        "    - fraudulent_transactions: pd.DataFrame. A DataFrame containing only the transactions classified as fraudulent.\n",
        "    \"\"\"\n",
        "\n",
        "    features = new_data.columns.tolist()\n",
        "    predictions = model.predict(new_data[features])\n",
        "    fraudulent_transactions = new_data[predictions == 1]\n",
        "\n",
        "    return fraudulent_transactions\n"
      ],
      "metadata": {
        "id": "_pHW0aCe_Ced"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = new_df.drop(\"Class\",axis=1)"
      ],
      "metadata": {
        "id": "Z0mzwsCw_pWD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Fraud_transaction = detect_fraudulent_transactions(model=load_model,new_data=dataset)\n",
        "Fraud_transaction.head()"
      ],
      "metadata": {
        "id": "zoUswd2b_RCF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Link for application: https://gc9hzmafjcithzgv4ycxrp.streamlit.app/\n",
        "\n",
        "Note:Please ensure that data do not contain null value or string value(Use the data provided with this google link)"
      ],
      "metadata": {
        "id": "kcB3b6XF_63a"
      }
    }
  ]
}